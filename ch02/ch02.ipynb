{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chapter 2 - First Steps with LangChain\n",
    "\n"
   ],
   "id": "777e208c3cd66126"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ChatDeepSeek example\n",
    "\n",
    "Taken from [langchain-deepseek](https://python.langchain.com/api_reference/deepseek/chat_models/langchain_deepseek.chat_models.ChatDeepSeek.html) documentation"
   ],
   "id": "e5af445acf0c3a6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T01:50:55.564489Z",
     "start_time": "2025-07-15T01:50:47.382106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # load environment variables from .env file\n",
    "\n",
    "# instantiate the llm\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", api_key=os.environ.get(\"DEEPSEEK_API_KEY\"))\n",
    "\n",
    "# construct a prompt\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to Spanish\"),\n",
    "    (\"human\", \"I love programming.\")\n",
    "]\n",
    "\n",
    "# pass the prompt to the llm and get a response\n",
    "response = llm.invoke(messages)\n",
    "print(response)"
   ],
   "id": "47e4933507c8a409",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Me encanta programar.  \\n\\n*(Alternative options depending on context:)*  \\n- **Amo programar.** (stronger emphasis)  \\n- **Disfruto mucho programando.** (\"I really enjoy programming\")  \\n\\nLet me know if you\\'d like a regional variation (e.g., Latin America vs. Spain) or a different tone!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 19, 'total_tokens': 90, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 19}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': 'db3b6cc4-4e7b-4ebf-853c-9b8ee4d94959', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--0fc05e59-ffb8-489c-b02f-323407d02631-0' usage_metadata={'input_tokens': 19, 'output_tokens': 71, 'total_tokens': 90, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Development testing\n",
    "\n",
    "During development, you might want to test your application without making an actual API calls. LangChain provides ```FakeListLLM``` for this purpose:"
   ],
   "id": "eab5ba80289e54a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T02:03:30.147364Z",
     "start_time": "2025-07-15T02:03:30.131276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.llms import FakeListLLM\n",
    "\n",
    "# create a fake LLM that always returns the same response\n",
    "\n",
    "fake_llm = FakeListLLM(responses=[\"Hello There\"])\n",
    "\n",
    "response = fake_llm.invoke(\"Any input will return 'Hello There'\")\n",
    "print(response)"
   ],
   "id": "26e6be801b5d9c77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello There\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Working with chat models",
   "id": "162ca542fbd6f5af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T19:25:33.910189Z",
     "start_time": "2025-07-15T19:25:14.969678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv() # load environment variables from .env file\n",
    "\n",
    "# instantiate llm\n",
    "chat = ChatDeepSeek(model=\"deepseek-chat\", api_key=os.environ.get(\"DEEPSEEK_API_KEY\"))\n",
    "\n",
    "# construct prompt\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a helpful programming assistant.\"),\n",
    "    HumanMessage(content=\"Write a Python function to calculate factorial.\"),\n",
    "]\n",
    "\n",
    "# invoke the llm\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)"
   ],
   "id": "5b533ccb5d4e0e82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hereâ€™s a Python function to calculate the factorial of a non-negative integer using both iterative and recursive approaches:\n",
      "\n",
      "### 1. Iterative Approach:\n",
      "```python\n",
      "def factorial_iterative(n):\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    result = 1\n",
      "    for i in range(1, n + 1):\n",
      "        result *= i\n",
      "    return result\n",
      "```\n",
      "\n",
      "### 2. Recursive Approach:\n",
      "```python\n",
      "def factorial_recursive(n):\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers.\")\n",
      "    if n == 0 or n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        return n * factorial_recursive(n - 1)\n",
      "```\n",
      "\n",
      "### Example Usage:\n",
      "```python\n",
      "num = 5\n",
      "print(f\"Iterative Factorial of {num}: {factorial_iterative(num)}\")\n",
      "print(f\"Recursive Factorial of {num}: {factorial_recursive(num)}\")\n",
      "```\n",
      "\n",
      "### Output:\n",
      "```\n",
      "Iterative Factorial of 5: 120\n",
      "Recursive Factorial of 5: 120\n",
      "```\n",
      "\n",
      "### Notes:\n",
      "- The factorial of `0` is `1` by definition.\n",
      "- Negative numbers raise a `ValueError` since factorial is not defined for them.\n",
      "- The iterative approach is generally more efficient for large numbers because it avoids stack overflow issues (unlike the recursive approach, which has a maximum recursion depth).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Chat prompt templates",
   "id": "d13d96e8036b0df0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T19:24:47.419972Z",
     "start_time": "2025-07-15T19:24:38.805776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# create a prompt template\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You're an English to Spanish translator.\"),\n",
    "    (\"human\", \"Translate this to Spanish: {text}.\")\n",
    "])\n",
    "\n",
    "# instantiate llm\n",
    "chat = ChatDeepSeek(model=\"deepseek-chat\", api_key=os.environ.get(\"DEEPSEEK_API_KEY\"))\n",
    "\n",
    "# create a message from the template\n",
    "formatted_messages = template.format(text=\"Hello, how are you?\")\n",
    "\n",
    "# invoke llm and get a response\n",
    "response = chat.invoke(formatted_messages)\n",
    "print(response.content)\n"
   ],
   "id": "35230a3f72694a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La traducciÃ³n al espaÃ±ol es:  \n",
      "\n",
      "**\"Hola, Â¿cÃ³mo estÃ¡s?\"**  \n",
      "\n",
      "Si necesitas una versiÃ³n mÃ¡s formal (por ejemplo, en un contexto profesional o con alguien a quien debes respeto), tambiÃ©n puedes usar:  \n",
      "\n",
      "**\"Hola, Â¿cÃ³mo estÃ¡ usted?\"**  \n",
      "\n",
      "Â¿Necesitas ayuda con algo mÃ¡s? ðŸ˜Š\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Simple workflows with LangChain Expression Language (LCEL)",
   "id": "1d4f039717471d88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T19:53:55.401649Z",
     "start_time": "2025-07-15T19:53:48.311687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# create components\n",
    "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", api_key=os.environ.get(\"DEEPSEEK_API_KEY\"))\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# chain them together using LCEL\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# execute the workflow with a single call\n",
    "response = chain.invoke({\"topic\": \"programming\"})\n",
    "print(response)\n"
   ],
   "id": "c832205c6eecc113",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a classic programming joke for you:\n",
      "\n",
      "**Why do programmers prefer dark mode?**  \n",
      "Because light attracts bugs!  \n",
      "\n",
      "*(And also because staring at a bright screen all day is painful... ðŸ˜†)*  \n",
      "\n",
      "Want another one? Just ask!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Complex chain example",
   "id": "1a8edc7a78166aae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T20:23:43.431404Z",
     "start_time": "2025-07-15T20:23:05.643891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatDeepSeek(model=\"deepseek-chat\", api_key=os.environ.get(\"DEEPSEEK_API_KEY\"))\n",
    "\n",
    "# first chain generates a story\n",
    "story_prompt = PromptTemplate.from_template(\"Write a short story about {topic}\")\n",
    "output_parser = StrOutputParser()\n",
    "story_chain = story_prompt | llm | output_parser\n",
    "\n",
    "# second chain analyses the story\n",
    "analysis_prompt = PromptTemplate.from_template(\"Analyze the following story's mood:\\n {story}\")\n",
    "analysis_chain = analysis_prompt | llm | output_parser\n",
    "\n",
    "# combine the chains\n",
    "story_with_analysis = story_chain | analysis_chain\n",
    "\n",
    "# run the combined chain\n",
    "response = story_with_analysis.invoke({\"topic\": \"a rainy day\"})\n",
    "print(response)"
   ],
   "id": "e342fbe5f83e72c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mood of **\"The Rainy Day\"** is **nostalgic, peaceful, and joyful**, with an underlying sense of warmth and childlike wonder.  \n",
      "\n",
      "### **Key Elements of the Mood:**  \n",
      "1. **Nostalgic & Reflective** â€“ Claraâ€™s love for rainy days and her spontaneous jump into a puddle evoke childhood memories, creating a wistful yet sweet tone.  \n",
      "2. **Peaceful & Serene** â€“ The description of the rain (\"the world softened,\" \"rhythmic patter\") gives a soothing, almost meditative quality.  \n",
      "3. **Joyful & Playful** â€“ Claraâ€™s laughter, Liam joining in, and their shared childlike behavior infuse the story with lighthearted happiness.  \n",
      "4. **Hopeful & Warm** â€“ The ending, where the sun reappears and Clara reflects on how rain brings out the best in people, leaves a comforting, optimistic impression.  \n",
      "\n",
      "### **Supporting Details:**  \n",
      "- **Imagery:** Soft rain, wet pavement, splashing puddlesâ€”all create a vivid, sensory-rich atmosphere.  \n",
      "- **Dialogue & Actions:** Clara and Liamâ€™s playful interaction reinforces the carefree mood.  \n",
      "- **Symbolism:** The rain acts as a metaphor for renewal and simple pleasures.  \n",
      "\n",
      "Overall, the mood is **uplifting and tender**, celebrating small moments of joy in everyday life.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "While this works, weâ€™ve lost the original story in our result â€“ we only get the analysis! In production applications, we typically want to preserve context throughout the chain:",
   "id": "b3b444d5d87e83ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T01:09:49.708782Z",
     "start_time": "2025-07-16T01:09:10.776647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# using RunnablePassthrough.assign to preserve data across the chain\n",
    "enhanced_chain = RunnablePassthrough.assign(\n",
    "    story=story_chain # add 'story' key with generated story\n",
    ").assign(\n",
    "    analysis=analysis_chain # add 'analysis' key with analysis of the story\n",
    ")\n",
    "\n",
    "# run the enhanced chain\n",
    "response = enhanced_chain.invoke({\"topic\": \"a rainy day\"})\n",
    "print(response.keys())\n",
    "print(response)\n"
   ],
   "id": "4ae75d30e3fa25a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['topic', 'story', 'analysis'])\n",
      "{'topic': 'a rainy day', 'story': '**The Rainy Day**  \\n\\nThe sky had been gray all morning, heavy with the promise of rain. Clara sat by the window, watching the first drops splatter against the glass, blurring the world outside. The rhythmic patter of rain against the roof was soothing, like a lullaby.  \\n\\nShe pulled on her yellow raincoat and stepped outside, the cool mist kissing her cheeks. Puddles had already formed on the sidewalk, and she couldnâ€™t resist jumping into the largest one, sending droplets flying.  \\n\\nA small, shivering kitten huddled under a nearby bench, its fur soaked. Clara knelt, offering her hand. The kitten hesitated, then pressed its tiny head against her palm. Wrapping it in her coat, she carried it home, where warmth and dry towels waited.  \\n\\nBy evening, the rain slowed to a drizzle. The kitten, now curled on Claraâ€™s lap, purred softly as she sipped hot cocoa. Outside, the world glistenedâ€”fresh and new.  \\n\\nSometimes, the best days were the rainy ones.', 'analysis': 'The mood of **\"The Rainy Day\"** is predominantly **peaceful, comforting, and heartwarming**, with subtle shifts that enhance its emotional depth. Hereâ€™s a breakdown:\\n\\n1. **Melancholic Yet Soothing (Opening)**  \\n   - The gray sky and heavy rain initially evoke a quiet, reflective mood, almost wistful. Words like *\"blurring the world outside\"* and *\"rhythmic patter\"* create a sense of calm solitude.  \\n\\n2. **Playful and Lighthearted (Middle)**  \\n   - Claraâ€™s actionsâ€”jumping in puddles, the *\"yellow raincoat\"*â€”introduce joy and childlike wonder. The imagery feels vibrant and carefree.  \\n\\n3. **Tender and Hopeful (Kitten Rescue)**  \\n   - The shivering kitten shifts the tone to gentle concern, then warmth as Clara helps it. Words like *\"pressed its tiny head against her palm\"* evoke tenderness and compassion.  \\n\\n4. **Cozy and Content (Ending)**  \\n   - The scene of Clara with the purring kitten, hot cocoa, and a glistening world resolves the story in a mood of quiet happiness. The rain transforms from gray to renewing, emphasizing gratitude and small joys.  \\n\\n**Overall Mood:**  \\nA **bittersweet yet uplifting** blendâ€”melancholy soothed by kindness, loneliness replaced by connection, and rain symbolizing renewal. It leaves the reader with a sense of **peace and hope**.  \\n\\n**Key Themes:** Comfort in solitude, the joy of small acts of kindness, and finding beauty in gloomy moments.'}\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
